{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3bf40b63",
   "metadata": {},
   "source": [
    "# 0.) Import the Credit Card Fraud Data From CCLE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c22346d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from google.colab import drive\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b621650",
   "metadata": {},
   "outputs": [],
   "source": [
    "drive.mount('/content/gdrive/', force_remount = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f61859fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"/content/gdrive/MyDrive/W24ML Code/Data/fraudTest.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d87e6c8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "972d84b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_select = df[[\"trans_date_trans_time\", \"category\", \"amt\", \"city_pop\", \"is_fraud\"]]\n",
    "\n",
    "df_select[\"trans_date_trans_time\"] = pd.to_datetime(df_select[\"trans_date_trans_time\"])\n",
    "df_select[\"time_var\"] = [i.second for i in df_select[\"trans_date_trans_time\"]]\n",
    "\n",
    "X = pd.get_dummies(df_select, [\"category\"]).drop([\"trans_date_trans_time\", \"is_fraud\"], axis = 1)\n",
    "y = df[\"is_fraud\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1380398",
   "metadata": {},
   "source": [
    "# 1.) Use scikit learn preprocessing to split the data into 70/30 in out of sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b188dc8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20b3bd9e",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d14e24a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = .3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8f38e36",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test, X_holdout, y_test, y_holdout = train_test_split(X_test, y_test, test_size = .5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c12ffcc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "X_holdout = scaler.transform(X_holdout)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05f49443",
   "metadata": {},
   "source": [
    "# 2.) Make three sets of training data (Oversample, Undersample and SMOTE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f16c5f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from imblearn.over_sampling import SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f00cb706",
   "metadata": {},
   "outputs": [],
   "source": [
    "ros = RandomOverSampler()\n",
    "over_X, over_y = ros.fit_resample(X_train, y_train)\n",
    "\n",
    "rus = RandomUnderSampler()\n",
    "under_X, under_y = rus.fit_resample(X_train, y_train)\n",
    "\n",
    "smote = SMOTE()\n",
    "smote_X, smote_y = smote.fit_resample(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbbe5bd2",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "187afa67",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea5194d1",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "960e10f2",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea5f6c68",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2160f8f",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5628db3a",
   "metadata": {},
   "source": [
    "# 3.) Train three logistic regression models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81373d6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4802a35",
   "metadata": {},
   "outputs": [],
   "source": [
    "over_log = LogisticRegression().fit(over_X, over_y)\n",
    "\n",
    "under_log = LogisticRegression().fit(under_X, under_y)\n",
    "\n",
    "smote_log = LogisticRegression().fit(smote_X, smote_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7971be94",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8050f26f",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1d91fc0",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fae19b68",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1953c5e9",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92524cd0",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "08615446",
   "metadata": {},
   "source": [
    "# 4.) Test the three models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "096bc3db",
   "metadata": {},
   "outputs": [],
   "source": [
    "over_log.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f6f63fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "under_log.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75428cf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "smote_log.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d9d5082",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We see SMOTE performing with higher accuracy but is ACCURACY really the best measure?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ea8cabf",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "7cedaf77",
   "metadata": {},
   "source": [
    "# 5.) Which performed best in Out of Sample metrics?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1876fff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sensitivity here in credit fraud is more important as seen from last class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57f64cfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7310058",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_true = y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcaa0671",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = over_log.predict(X_test)\n",
    "cm = confusion_matrix(y_true, y_pred)\n",
    "cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2cf1a66",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Over Sample Sensitivity : \", cm[1,1] /( cm[1,0] + cm[1,1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f9119d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = under_log.predict(X_test)\n",
    "cm = confusion_matrix(y_true, y_pred)\n",
    "cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdb4be2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Under Sample Sensitivity : \", cm[1,1] /( cm[1,0] + cm[1,1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93e3e312",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = smote_log.predict(X_test)\n",
    "cm = confusion_matrix(y_true, y_pred)\n",
    "cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90f6c28a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"SMOTE Sample Sensitivity : \", cm[1,1] /( cm[1,0] + cm[1,1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c12db9f",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2edf8808",
   "metadata": {},
   "source": [
    "# 6.) Pick two features and plot the two classes before and after SMOTE."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e8c460c",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_temp = pd.concat([X_train, y_train], axis =1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "914cf2de",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aad3717c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#plt.scatter(raw_temp[raw_temp[\"is_fraud\"] == 0][\"amt\"], raw_temp[raw_temp[\"is_fraud\"] == 0][\"city_pop\"])\n",
    "\n",
    "plt.scatter(raw_temp[raw_temp[\"is_fraud\"] == 1][\"amt\"], raw_temp[raw_temp[\"is_fraud\"] == 1][\"city_pop\"])\n",
    "plt.legend([\"Fraud\", \"Not Fraud\"])\n",
    "plt.xlabel(\"Amount\")\n",
    "plt.ylabel(\"Population\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43a0dd9e",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "\n",
    "raw_temp = pd.concat([smote_X, smote_y], axis =1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8181f34e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#plt.scatter(raw_temp[raw_temp[\"is_fraud\"] == 0][\"amt\"], raw_temp[raw_temp[\"is_fraud\"] == 0][\"city_pop\"])\n",
    "\n",
    "plt.scatter(raw_temp[raw_temp[\"is_fraud\"] == 1][\"amt\"], raw_temp[raw_temp[\"is_fraud\"] == 1][\"city_pop\"])\n",
    "plt.legend([ \"Not Fraud\", \"Fraud\"])\n",
    "plt.xlabel(\"Amount\")\n",
    "plt.ylabel(\"Population\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a09a010",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f7e699cd",
   "metadata": {},
   "source": [
    "# 7.) We want to compare oversampling, Undersampling and SMOTE across our 3 models (Logistic Regression, Logistic Regression Lasso and Decision Trees).\n",
    "\n",
    "# Make a dataframe that has a dual index and 9 Rows.\n",
    "# Calculate: Sensitivity, Specificity, Precision, Recall and F1 score. for out of sample data.\n",
    "# Notice any patterns across perfomance for this model. Does one totally out perform the others IE. over/under/smote or does a model perform better DT, Lasso, LR?\n",
    "# Choose what you think is the best model and why. test on Holdout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4360ce38",
   "metadata": {
    "lines_to_next_cell": 3
   },
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import confusion_matrix, precision_score, recall_score, f1_score\n",
    "import pandas as pd"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "formats": "py:percent,ipynb",
   "main_language": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
